[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[project]
authors = [
    { name = "Aaron Pham", email = "aarnphm@bentoml.com" },
    { name = "BentoML Team", email = "contact@bentoml.com" },
]
classifiers = [
    "Development Status :: 4 - Beta",
    "License :: OSI Approved :: Apache Software License",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3 :: Only",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
]
dependencies = [
    # bentoml[io] includes pydantic, PIL, filetype, pandas and numpy
    # bentoml[grpc,grpc-reflection] include grpcio, grpcio-reflection
    "bentoml",
    "filetype",
    "Pillow",
    "protobuf",
    "grpcio",
    "grpcio-health-checking",
    "opentelemetry-instrumentation-grpc==0.35b0",
    "grpcio-reflection",
    "httpx[http2]",
    # transformers[torch] includes torch and transformers
    "transformers[torch,accelerate,tokenizers,onnxruntime,onnx]>=4.29.0",
    # BetterTransformer support for inference.
    "optimum",
    # Super fast JSON serialization
    "orjson",
    "inflection",
    # pydantic 2 ftw
    "pydantic",
    # black for generating service file.
    "black[jupyter]==23.3.0",
]
description = 'OpenLLM: REST/gRPC API server for running any open Large-Language Model - StableLM, Llama, Alpaca, Dolly, Flan-T5, Custom'
dynamic = ["version"]
keywords = [
    "MLOps",
    "AI",
    "BentoML",
    "Model Serving",
    "Model Deployment",
    "LLMOps",
    "Large Language Model",
    "Generative AI",
    "Stable Diffusion",
    "StableLM",
    "Alpaca",
    "PyTorch",
    "Transformers",
]
license = "Apache-2.0"
name = "openllm"
readme = "README.md"
requires-python = ">=3.8"

[project.optional-dependencies]
all = ['openllm[fine-tune]', 'openllm[chatglm]', 'openllm[falcon]', 'openllm[flan-t5]', 'openllm[starcoder]']
chatglm = ['cpm_kernels', 'sentencepiece']
falcon = ['einops']
fine-tune = ['peft', 'bitsandbytes', 'datasets']
flan-t5 = ['flax', 'jax', 'jaxlib', 'tensorflow']
starcoder = ['bitsandbytes']

[project.urls]
Documentation = "https://github.com/llmsys/openllm#readme"
Issues = "https://github.com/llmsys/openllm/issues"
Source = "https://github.com/llmsys/openllm"

[project.scripts]
openllm = "openllm.cli:cli"

[tool.hatch.version]
path = "src/openllm/__about__.py"

[tool.hatch.metadata]
allow-direct-references = true

[tool.hatch.envs.default]
dependencies = [
    "coverage[toml]>=6.5",
    "pytest",
    "pytest-asyncio>=0.21.0",
    "pytest-xdist[psutil]",
    "pytest-cov",
    "pytest-mock",
    "pytest-randomly",
    "pytest-rerunfailures",
    "pre-commit",
]
[tool.hatch.envs.default.scripts]
cov = ["test-cov", "cov-report"]
cov-report = ["- coverage combine", "coverage report"]
setup = "pre-commit install"
test = "pytest {args:tests}"
test-cov = "coverage run -m pytest {args:tests}"

[[tool.hatch.envs.all.matrix]]
python = ["3.8", "3.9", "3.10", "3.11"]

[tool.hatch.envs.dev]
dependencies = ["ruff>=0.0.243", "pyright", "hatch"]
detached = true

[tool.hatch.envs.dev.scripts]
all = ["fmt", "typing"]
fmt = ["black {args:.}", "black --pyi {args:typings/}", "ruff --fix {args:.}", "style"]
style = ["ruff {args:.}", "black --check --diff {args:.}"]
typing = "pyright {args:src/openllm tests}"

[tool.pytest.ini_options]
addopts = ["-rfEX", "-pno:warnings"]
python_files = ["test_*.py", "*_test.py"]
testpaths = ["tests"]

[tool.black]
exclude = '''
(
  /(
      \.eggs
    | \.git
    | \.tox
    | \.venv
    | _build
    | .build
    | bazel-*
    | build
    | venv
    | lib
    | dist
  )/
  | src/openllm/__about__.py
)
'''
line-length = 120
target-version = ["py311"]

[tool.ruff]
ignore = [
    # Allow non-abstract empty methods in abstract base classes
    "B027",
    # Allow boolean positional values in function calls, like `dict.get(... True)`
    "FBT003",
    # Ignore checks for possible passwords
    "S105",
    "S106",
    "S107",
    # Ignore complexity
    "C901",
    "PLR0911",
    "PLR0912",
    "PLR0913",
    "PLR0915",
]
line-length = 120
target-version = "py311"
unfixable = [
    "F401", # Don't touch unused imports, just warn about it.
]

[tool.ruff.pydocstyle]
convention = "google"

[tool.ruff.isort]
known-first-party = ["openllm", "bentoml", 'transformers']
lines-after-imports = 2

[tool.ruff.flake8-quotes]
inline-quotes = "single"

[tool.ruff.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
"__init__.py" = ["E402", "F401", "F403", "F811"]
"tests/**/*" = ["PLR2004", "S101", "TID252"]

[tool.pyright]
analysis.useLibraryCodeForTypes = true
enableTypeIgnoreComments = true
include = ["src/", "tests/"]
pythonVersion = "3.11"
reportMissingImports = "none"
reportMissingModuleSource = "warning"
reportMissingTypeStubs = "warning"
reportUnknownMemberType = "warning"
reportUnknownVariableType = "warning"
strictDictionaryInference = true
strictListInference = true
strictParameterNoneValue = true
strictSetInference = true
typeCheckingMode = "strict"


[tool.coverage.run]
branch = true
omit = ["src/openllm/__about__.py"]
parallel = true
source_pkgs = ["openllm", "tests"]

[tool.coverage.paths]
openllm = ["src/openllm", "*/openllm/src/openllm"]
tests = ["tests", "*/openllm/tests"]

[tool.coverage.report]
exclude_lines = ["no cov", "if __name__ == .__main__.:", "if t.TYPE_CHECKING:"]
