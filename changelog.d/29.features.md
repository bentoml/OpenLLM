OpenLLM now seamlessly integrates with HuggingFace Agents.
Replace the HfAgent endpoint with a running remote server.

```python
import transformers

agent = transformers.HfAgent("http://localhost:3000/hf/agent")  # URL that runs the OpenLLM server

agent.run("Is the following `text` positive or negative?", text="I don't like how this models is generate inputs")
```

Note that only `starcoder` is currently supported for agent feature.

To use it from the `openllm.client`, do:
```python
import openllm

client = openllm.client.HTTPClient("http://123.23.21.1:3000")

client.ask_agent(
    task="Is the following `text` positive or negative?",
    text="What are you thinking about?",
    agent_type="hf",
)
```
