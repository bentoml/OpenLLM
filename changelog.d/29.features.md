OpenLLM now seamlessly integrates with HuggingFace Agents.
Replace the HfAgent endpoint with a running remote server.

```python
import transformers

agent = transformers.HfAgent("http://localhost:3000/hf/agent")  # URL that runs the OpenLLM server

agent.run("Is the following `text` positive or negative?", text="I don't like how this models is generate inputs")
```

Note that only `starcoder` is currently supported for agent feature.

To use it from the `openllm.client`, do:
```python
import openllm

client = openllm.client.HTTPClient("http://123.23.21.1:3000")

client.agent(
    prompt="Is the following `text` positive or negative?", 
    text="What are you thinking about?", 
    agent_type="hf",
)
```
